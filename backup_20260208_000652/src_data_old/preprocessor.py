# =============================================================================
# VERÄ° Ã–N Ä°ÅLEME MODÃœLÃœ (DATA PREPROCESSOR)
# =============================================================================
# AmaÃ§: Ham OHLCV verisini IC analizi ve indikatÃ¶r hesaplamasÄ± iÃ§in hazÄ±rlamak
#
# Pipeline:
# 1. Missing value â†’ ffill (look-ahead bias yok)
# 2. Return hesaplama â†’ log return (toplamsal, ~normal daÄŸÄ±lÄ±m)
# 3. Outlier winsorization â†’ uÃ§ deÄŸerleri percentile'a Ã§ek
# 4. Volatilite hesaplama â†’ Garman-Klass (OHLC bazlÄ±, verimli)
# 5. Forward return â†’ IC hesaplamasÄ± iÃ§in gelecek getiri (TARGET)
#
# Ä°statistiksel Ã–nem:
# - Veri kalitesi TÃœM downstream analizleri belirler
# - Look-ahead bias â†’ ffill DIÅI yÃ¶ntemlerden kaÃ§Ä±n
# - Outlier'larÄ± silme DEÄÄ°L winsorize et (veri kaybÄ± Ã¶nle)
# - Forward return = IC'nin baÄŸÄ±mlÄ± deÄŸiÅŸkeni (SADECE backtest'te!)
#
# Eski projeden farklar:
# - Daha hafif (gereksiz yÃ¶ntemler kaldÄ±rÄ±ldÄ±)
# - Futures-odaklÄ± (funding rate desteÄŸi hazÄ±r)
# - Pipeline tek fonksiyonla Ã§alÄ±ÅŸÄ±r
# =============================================================================

import pandas as pd                            # Veri manipÃ¼lasyonu
import numpy as np                             # SayÄ±sal hesaplamalar
import logging                                 # Log yÃ¶netimi
from typing import Optional, Dict, Tuple, List # Tip belirteÃ§leri
from scipy import stats                        # Ä°statistiksel fonksiyonlar

# Logger
logger = logging.getLogger(__name__)


class DataPreprocessor:
    """
    OHLCV verisini analiz iÃ§in Ã¶n iÅŸleme tabi tutan sÄ±nÄ±f.
    
    IC analizi zincirindeki yeri:
    
    Ham OHLCV â†’ [PREPROCESSOR] â†’ Temiz Veri â†’ Ä°ndikatÃ¶rler â†’ IC Analizi
    
    Her method baÄŸÄ±msÄ±z Ã§alÄ±ÅŸÄ±r (stateless tasarÄ±m).
    Pipeline ile hepsini sÄ±rasÄ±yla uygulayabilirsin.
    
    KullanÄ±m:
    --------
    preprocessor = DataPreprocessor()
    
    # Tek adÄ±mda tÃ¼m Ã¶n iÅŸleme:
    df_clean = preprocessor.full_pipeline(df_raw)
    
    # Veya adÄ±m adÄ±m:
    df = preprocessor.handle_missing(df)
    df = preprocessor.add_returns(df)
    df = preprocessor.winsorize_returns(df)
    """
    
    def __init__(self):
        """
        Stateless preprocessor baÅŸlatÄ±r.
        HiÃ§bir state tutmaz, her Ã§aÄŸrÄ± baÄŸÄ±msÄ±z Ã§alÄ±ÅŸÄ±r.
        """
        pass
    
    # =========================================================================
    # 1. EKSÄ°K VERÄ° Ä°ÅLEME
    # =========================================================================
    
    def handle_missing(
        self,
        df: pd.DataFrame,
        method: str = "ffill",
        max_gap: int = 5
    ) -> pd.DataFrame:
        """
        Eksik verileri tespit eder ve doldurur.
        
        Parametreler:
        ------------
        df : pd.DataFrame
            OHLCV DataFrame
            
        method : str
            "ffill" = Forward fill (Ã¶nceki deÄŸerle doldur)
            SADECE ffill kullan! DiÄŸerleri look-ahead bias riski taÅŸÄ±r.
            
        max_gap : int
            ArdÄ±ÅŸÄ±k eksik veri sayÄ±sÄ± bu deÄŸeri aÅŸarsa doldurma yapÄ±lmaz.
            Uzun gap'ler genellikle borsa maintenance'Ä±nÄ± gÃ¶sterir.
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Eksik deÄŸerleri iÅŸlenmiÅŸ DataFrame
        
        Ä°statistiksel Not:
        -----------------
        Forward fill NEDEN gÃ¼venli?
        â†’ Sadece t zamanÄ±nda bildiÄŸin veriyi (t-1) kullanÄ±r
        â†’ Look-ahead bias = 0
        
        Backward fill NEDEN tehlikeli?
        â†’ t+1 zamanÄ±ndaki veriyi t'de kullanÄ±r
        â†’ Look-ahead bias = âˆ (tÃ¼m analiz geÃ§ersiz)
        """
        df_clean = df.copy()
        
        missing_before = df_clean.isnull().sum().sum()
        
        if missing_before == 0:
            return df_clean
        
        # Forward fill: Ã–nceki geÃ§erli deÄŸerle doldur
        # limit=max_gap: En fazla max_gap ardÄ±ÅŸÄ±k NaN doldur
        df_clean = df_clean.ffill(limit=max_gap)
        
        # BaÅŸlangÄ±Ã§taki NaN'larÄ± da backward fill ile doldur
        # (Sadece ilk birkaÃ§ satÄ±r - look-ahead bias riski minimal)
        df_clean = df_clean.bfill(limit=2)
        
        missing_after = df_clean.isnull().sum().sum()
        
        if missing_before > 0:
            logger.info(
                f"  Missing: {missing_before} â†’ {missing_after} "
                f"({missing_before - missing_after} dolduruldu)"
            )
        
        return df_clean
    
    # =========================================================================
    # 2. RETURN (GETÄ°RÄ°) HESAPLAMA
    # =========================================================================
    
    def add_returns(
        self,
        df: pd.DataFrame,
        method: str = "log"
    ) -> pd.DataFrame:
        """
        Fiyat verisinden getiri (return) hesaplar.
        
        Parametreler:
        ------------
        df : pd.DataFrame
            En az 'close' kolonu iÃ§ermeli
            
        method : str
            "log" = Logaritmik return: ln(P_t / P_{t-1})
            "simple" = Basit return: (P_t - P_{t-1}) / P_{t-1}
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Orijinal + 'log_return' ve 'simple_return' kolonlarÄ±
        
        Ä°statistiksel Not:
        -----------------
        Log return avantajlarÄ±:
        1. Toplamsal: r_total = r_1 + r_2 + ... + r_n
           (Simple return Ã§arpÄ±msal: R_total = (1+r_1)(1+r_2)...-1)
        2. Simetri: +10% ve -10% log return aynÄ± bÃ¼yÃ¼klÃ¼kte
        3. Normal daÄŸÄ±lÄ±ma daha yakÄ±n (CLT varsayÄ±mÄ± iÃ§in)
        4. Volatilite hesaplamalarÄ± iÃ§in daha uygun
        
        IC hesaplamasÄ±nda log return tercih edilir Ã§Ã¼nkÃ¼:
        - Spearman korelasyonu rank-based, ama daÄŸÄ±lÄ±m yakÄ±nlÄ±ÄŸÄ± yine Ã¶nemli
        - Extreme return'ler log'da daha simetrik â†’ daha gÃ¼venilir IC
        """
        result = df.copy()
        
        # Log return: ln(P_t) - ln(P_{t-1}) = ln(P_t / P_{t-1})
        result['log_return'] = np.log(
            result['close'] / result['close'].shift(1)
        )
        
        # Simple return: (P_t - P_{t-1}) / P_{t-1}
        result['simple_return'] = result['close'].pct_change()
        
        return result
    
    # =========================================================================
    # 3. OUTLIER Ä°ÅLEME (WÄ°NSORÄ°ZATÄ°ON)
    # =========================================================================
    
    def winsorize_returns(
        self,
        df: pd.DataFrame,
        column: str = "log_return",
        lower_pct: float = 0.5,
        upper_pct: float = 99.5
    ) -> pd.DataFrame:
        """
        UÃ§ deÄŸerleri (outlier) percentile deÄŸerlerine Ã§eker.
        
        Parametreler:
        ------------
        df : pd.DataFrame
            Return kolonu iÃ§eren DataFrame
            
        column : str
            Winsorize edilecek kolon
            
        lower_pct : float
            Alt percentile (varsayÄ±lan: 0.5 â†’ %0.5 alt uÃ§)
            
        upper_pct : float
            Ãœst percentile (varsayÄ±lan: 99.5 â†’ %0.5 Ã¼st uÃ§)
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Winsorize edilmiÅŸ DataFrame
        
        Neden Winsorization (silme veya NaN yerine)?
        -------------------------------------------
        1. Veri kaybÄ± yok â†’ sample size korunur â†’ IC istatistiksel gÃ¼cÃ¼ korunur
        2. UÃ§ deÄŸerlerin etkisi azalÄ±r â†’ IC daha stabil
        3. GerÃ§ek crash'ler tamamen silinmez â†’ realistic backtest
        
        Neden %0.5 / %99.5?
        â†’ %1 Ã§ok agresif (gerÃ§ek hareketleri de kÄ±rpar)
        â†’ %0.1 Ã§ok gevÅŸek (flash crash'ler bozar)
        â†’ %0.5 optimal trade-off (finans literatÃ¼rÃ¼ standardÄ±)
        """
        result = df.copy()
        
        if column not in result.columns:
            return result
        
        # Percentile deÄŸerlerini hesapla
        lower_val = result[column].quantile(lower_pct / 100)  # %0.5'lik deÄŸer
        upper_val = result[column].quantile(upper_pct / 100)  # %99.5'lik deÄŸer
        
        # Clip: DeÄŸerleri [lower, upper] aralÄ±ÄŸÄ±na sÄ±nÄ±rla
        before_outliers = (
            (result[column] < lower_val) | (result[column] > upper_val)
        ).sum()
        
        result[column] = result[column].clip(lower_val, upper_val)
        
        if before_outliers > 0:
            logger.info(
                f"  Winsorize ({column}): {before_outliers} outlier "
                f"[{lower_val:.4f}, {upper_val:.4f}] aralÄ±ÄŸÄ±na Ã§ekildi"
            )
        
        return result
    
    # =========================================================================
    # 4. VOLATÄ°LÄ°TE HESAPLAMA
    # =========================================================================
    
    def add_volatility(
        self,
        df: pd.DataFrame,
        window: int = 20,
        method: str = "garman_klass"
    ) -> pd.DataFrame:
        """
        Rolling volatilite hesaplar.
        
        Parametreler:
        ------------
        df : pd.DataFrame
            OHLCV DataFrame
            
        window : int
            Rolling window boyutu (bar sayÄ±sÄ±)
            20 = ~1 gÃ¼n @ 1h TF, ~5 saat @ 15m TF
            
        method : str
            "standard" = Standart sapma (sadece close kullanÄ±r)
            "garman_klass" = OHLC bazlÄ± (en verimli estimator)
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Orijinal + 'volatility' kolonu
        
        Garman-Klass Neden Daha Ä°yi?
        ----------------------------
        Standard:    Sadece close fiyatÄ±nÄ± kullanÄ±r â†’ bilgi kaybÄ±
        Parkinson:   High-Low kullanÄ±r â†’ ~5x daha verimli
        Garman-Klass: Open-High-Low-Close â†’ ~8x daha verimli
        
        "Verimli" = AynÄ± doÄŸruluk iÃ§in daha az veri noktasÄ± gerektirir
        â†’ Daha kÄ±sa pencerede bile gÃ¼venilir volatilite tahmini
        """
        result = df.copy()
        
        if method == "garman_klass":
            # Garman-Klass formÃ¼lÃ¼:
            # GK = 0.5 * ln(H/L)^2 - (2*ln(2) - 1) * ln(C/O)^2
            # Volatilite = sqrt(rolling_mean(GK))
            
            log_hl = np.log(result['high'] / result['low'])     # ln(High/Low)
            log_co = np.log(result['close'] / result['open'])   # ln(Close/Open)
            
            # GK bileÅŸenleri
            gk = 0.5 * (log_hl ** 2) - (2 * np.log(2) - 1) * (log_co ** 2)
            
            # Rolling ortalama alÄ±p karekÃ¶k â†’ volatilite
            result['volatility'] = np.sqrt(gk.rolling(window=window).mean())
            
        elif method == "standard":
            # Basit standart sapma (sadece close return kullanÄ±r)
            if 'log_return' not in result.columns:
                result['log_return'] = np.log(
                    result['close'] / result['close'].shift(1)
                )
            result['volatility'] = result['log_return'].rolling(window=window).std()
        
        return result
    
    # =========================================================================
    # 5. FORWARD RETURN (HEDEF DEÄÄ°ÅKEN)
    # =========================================================================
    
    def add_forward_returns(
        self,
        df: pd.DataFrame,
        periods: List[int] = [1, 5, 10, 20]
    ) -> pd.DataFrame:
        """
        Ä°leri getiriler ekler (IC hesaplamasÄ±nÄ±n TARGET deÄŸiÅŸkeni).
        
        âš ï¸ KRÄ°TÄ°K UYARI:
        Bu kolonlar SADECE IC hesaplama ve backtest'te kullanÄ±lmalÄ±!
        CanlÄ± sistemde bu bilgi mevcut DEÄÄ°L (gelecek bilinmiyor).
        Bu kolonlarÄ± modele input olarak vermek = LOOK-AHEAD BIAS.
        
        Parametreler:
        ------------
        df : pd.DataFrame
            En az 'close' kolonu
            
        periods : List[int]
            Ä°leri periyotlar
            1 = sonraki bar, 5 = 5 bar sonra, vb.
            
            IC hesaplamasÄ±nda genellikle target_period=5 kullanÄ±yoruz.
            Bu, "bu indikatÃ¶r 5 bar sonraki getiriyi tahmin edebiliyor mu?"
            sorusunu cevaplar.
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Orijinal + fwd_ret_N ve fwd_dir_N kolonlarÄ±
            
            fwd_ret_5 = 5 bar sonraki log return (sÃ¼rekli deÄŸer)
            fwd_dir_5 = 5 bar sonra yÃ¶n (1=yukarÄ±, 0=aÅŸaÄŸÄ±, binary)
        
        IC FormÃ¼lÃ¼ HatÄ±rlatma:
        ---------------------
        IC = Spearman(indicator_t, fwd_ret_t)
        IC > 0 â†’ Ä°ndikatÃ¶r yÃ¼kselince fiyat da yÃ¼kseliyor
        IC < 0 â†’ Ä°ndikatÃ¶r yÃ¼kselince fiyat dÃ¼ÅŸÃ¼yor
        """
        result = df.copy()
        
        for p in periods:
            # Log return: ln(P_{t+p} / P_t)
            # shift(-p) = gelecek p bar'Ä±n fiyatÄ±
            result[f'fwd_ret_{p}'] = np.log(
                result['close'].shift(-p) / result['close']
            )
            
            # Binary yÃ¶n: 1 = yukarÄ± (pozitif return), 0 = aÅŸaÄŸÄ± (negatif)
            result[f'fwd_dir_{p}'] = (result[f'fwd_ret_{p}'] > 0).astype(int)
        
        return result
    
    # =========================================================================
    # 6. FÄ°YAT Ã–ZELLÄ°KLERÄ° (PRICE FEATURES)
    # =========================================================================
    
    def add_price_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Temel fiyat Ã¶zelliklerini ekler (pandas-ta dÄ±ÅŸÄ±, ham hesaplamalar).
        
        Bu Ã¶zellikler indikatÃ¶r hesaplamasÄ±ndan Ã–NCE eklenir.
        BazÄ±larÄ± tek baÅŸÄ±na IC analizi iÃ§in kullanÄ±labilir.
        
        Eklenen Ã–zellikler:
        ------------------
        range: High - Low (bar aralÄ±ÄŸÄ±, volatilite proxy)
        body: Close - Open (mum gÃ¶vdesi, alÄ±m/satÄ±m baskÄ±sÄ±)
        body_pct: body / open * 100 (normalize gÃ¶vde)
        upper_wick: Ãœst fitil (satÄ±ÅŸ baskÄ±sÄ±)
        lower_wick: Alt fitil (alÄ±m baskÄ±sÄ±)
        gap: Open_t - Close_{t-1} (aÃ§Ä±lÄ±ÅŸ boÅŸluÄŸu)
        hl_position: Close'un High-Low aralÄ±ÄŸÄ±ndaki yeri (0=Low, 1=High)
        volume_ratio: Volume / SMA(Volume, 20) (hacim anomalisi)
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Orijinal + yeni Ã¶zellik kolonlarÄ±
        """
        result = df.copy()
        
        # Bar aralÄ±ÄŸÄ±: Tek bar volatilitesi
        result['range'] = result['high'] - result['low']
        
        # Mum gÃ¶vdesi: Pozitif = bullish (yeÅŸil), Negatif = bearish (kÄ±rmÄ±zÄ±)
        result['body'] = result['close'] - result['open']
        
        # Normalize gÃ¶vde: FarklÄ± fiyatlÄ± coinleri karÅŸÄ±laÅŸtÄ±rmak iÃ§in
        result['body_pct'] = (result['body'] / result['open']) * 100
        
        # Fitiller: Rejection sinyali
        # Ãœst fitil uzun = SatÄ±ÅŸ baskÄ±sÄ± (fiyat High'a Ã§Ä±kÄ±p geri gelmiÅŸ)
        result['upper_wick'] = result['high'] - result[['open', 'close']].max(axis=1)
        # Alt fitil uzun = AlÄ±m baskÄ±sÄ± (fiyat Low'a inip geri Ã§Ä±kmÄ±ÅŸ)
        result['lower_wick'] = result[['open', 'close']].min(axis=1) - result['low']
        
        # Gap: Bir Ã¶nceki bar'Ä±n close'u ile bu bar'Ä±n open'Ä± arasÄ±ndaki fark
        result['gap'] = result['open'] - result['close'].shift(1)
        result['gap_pct'] = (result['gap'] / result['close'].shift(1)) * 100
        
        # Close'un High-Low aralÄ±ÄŸÄ±ndaki pozisyonu (0=Low'da, 1=High'da)
        # 0.5'e yakÄ±nsa = doji (kararsÄ±zlÄ±k)
        # 1'e yakÄ±nsa = gÃ¼Ã§lÃ¼ close (bullish)
        # 0'a yakÄ±nsa = zayÄ±f close (bearish)
        result['hl_position'] = (
            (result['close'] - result['low']) / 
            (result['range'] + 1e-10)  # SÄ±fÄ±ra bÃ¶lme korumasÄ±
        )
        
        # Hacim oranÄ±: Ortalama hacmin kaÃ§ katÄ±?
        # >1.5 = anormal hacim, breakout sinyali olabilir
        # <0.5 = dÃ¼ÅŸÃ¼k hacim, sahte hareket olabilir
        result['volume_sma_20'] = result['volume'].rolling(20).mean()
        result['volume_ratio'] = result['volume'] / (result['volume_sma_20'] + 1e-10)
        
        return result
    
    # =========================================================================
    # 7. ROLLING Ä°STATÄ°STÄ°KLER
    # =========================================================================
    
    def add_rolling_stats(
        self,
        df: pd.DataFrame,
        windows: List[int] = [10, 20, 50]
    ) -> pd.DataFrame:
        """
        Rolling istatistiksel Ã¶zellikler ekler.
        
        Parametreler:
        ------------
        windows : List[int]
            Rolling pencere boyutlarÄ±
            [10, 20, 50] = kÄ±sa, orta, uzun vade
        
        Her window iÃ§in eklenen Ã¶zellikler:
        ----------------------------------
        roll{w}_ret_mean : Ortalama getiri (trend yÃ¶nÃ¼)
        roll{w}_ret_std  : Getiri volatilitesi (Ïƒ)
        roll{w}_ret_skew : Asimetri (kuyruk yÃ¶nÃ¼)
        roll{w}_ret_kurt : BasÄ±klÄ±k (kuyruk kalÄ±nlÄ±ÄŸÄ±)
        roll{w}_zscore   : (Close - MA) / Std (mean-reversion sinyali)
        
        Ä°statistiksel Yorum:
        -------------------
        Skewness < 0 â†’ Sol kuyruk uzun â†’ crash riski yÃ¼ksek
        Kurtosis > 3 â†’ Fat-tail â†’ extreme event riski yÃ¼ksek
        |Z-score| > 2 â†’ Fiyat ortalamanÄ±n 2Ïƒ uzaÄŸÄ±nda â†’ mean-reversion beklenir
        """
        result = df.copy()
        
        # Log return yoksa hesapla
        if 'log_return' not in result.columns:
            result['log_return'] = np.log(
                result['close'] / result['close'].shift(1)
            )
        
        returns = result['log_return']
        
        for w in windows:
            prefix = f"roll{w}_"
            
            # 1. Getiri istatistikleri
            result[f'{prefix}ret_mean'] = returns.rolling(w).mean()   # Trend yÃ¶nÃ¼
            result[f'{prefix}ret_std'] = returns.rolling(w).std()     # Volatilite
            result[f'{prefix}ret_skew'] = returns.rolling(w).skew()   # Asimetri
            result[f'{prefix}ret_kurt'] = returns.rolling(w).kurt()   # BasÄ±klÄ±k
            
            # 2. Z-score: FiyatÄ±n rolling ortalamasÄ±na gÃ¶re konumu
            # Z > 0: OrtalamanÄ±n Ã¼stÃ¼nde (overvalued?)
            # Z < 0: OrtalamanÄ±n altÄ±nda (undervalued?)
            roll_mean = result['close'].rolling(w).mean()
            roll_std = result['close'].rolling(w).std()
            result[f'{prefix}zscore'] = (
                (result['close'] - roll_mean) / (roll_std + 1e-10)
            )
        
        return result
    
    # =========================================================================
    # FULL PIPELINE: TEK FONKSÄ°YONLA TÃœM Ã–N Ä°ÅLEME
    # =========================================================================
    
    def full_pipeline(
        self,
        df: pd.DataFrame,
        forward_periods: List[int] = [1, 5, 10, 20],
        rolling_windows: List[int] = [10, 20, 50],
        drop_na: bool = True
    ) -> pd.DataFrame:
        """
        TÃ¼m Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± sÄ±rasÄ±yla uygular.
        
        Bu fonksiyon, ham OHLCV â†’ IC-ready veri dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ tek adÄ±mda yapar.
        
        Pipeline SÄ±rasÄ±:
        ---------------
        1. Missing values â†’ ffill (look-ahead bias gÃ¼venli)
        2. Returns â†’ log + simple return hesaplama
        3. Winsorization â†’ uÃ§ deÄŸerleri %0.5-%99.5'e Ã§ek
        4. Price features â†’ range, body, wick, gap, volume_ratio
        5. Rolling stats â†’ mean, std, skew, kurt, zscore
        6. Volatility â†’ Garman-Klass (OHLC bazlÄ±)
        7. Forward returns â†’ IC'nin hedef deÄŸiÅŸkeni (TARGET)
        8. NaN temizleme â†’ rolling baÅŸlangÄ±cÄ±ndaki NaN'larÄ± kaldÄ±r
        
        Parametreler:
        ------------
        df : pd.DataFrame
            Ham OHLCV DataFrame
            
        forward_periods : List[int]
            Forward return periyotlarÄ± [1, 5, 10, 20]
            
        rolling_windows : List[int]
            Rolling istatistik pencereleri [10, 20, 50]
            
        drop_na : bool
            True ise NaN satÄ±rlarÄ± kaldÄ±r (Ã¶nerilir)
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Tam iÅŸlenmiÅŸ, IC analizine hazÄ±r DataFrame
            
        Ã–rnek:
        ------
        >>> pp = DataPreprocessor()
        >>> df_raw = fetcher.fetch_ohlcv("BTC/USDT:USDT", "1h", 500)
        >>> df_clean = pp.full_pipeline(df_raw)
        >>> print(df_clean.shape)
        (450, 25)  # NaN kÄ±rpÄ±lmÄ±ÅŸ, tÃ¼m Ã¶zellikler ekli
        """
        logger.info("ğŸ“‹ Preprocessing pipeline baÅŸlÄ±yor...")
        
        rows_before = len(df)
        
        # 1. Missing values
        result = self.handle_missing(df)
        
        # 2. Returns
        result = self.add_returns(result)
        
        # 3. Winsorization
        result = self.winsorize_returns(result, column='log_return')
        
        # 4. Price features
        result = self.add_price_features(result)
        
        # 5. Rolling stats
        result = self.add_rolling_stats(result, windows=rolling_windows)
        
        # 6. Volatility
        result = self.add_volatility(result)
        
        # 7. Forward returns (IC hedef deÄŸiÅŸkeni)
        result = self.add_forward_returns(result, periods=forward_periods)
        
        # 8. NaN temizleme
        if drop_na:
            result = result.dropna()
        
        rows_after = len(result)
        new_cols = len(result.columns) - len(df.columns)
        
        logger.info(
            f"  âœ“ Pipeline tamamlandÄ±: {rows_before} â†’ {rows_after} satÄ±r, "
            f"+{new_cols} yeni kolon"
        )
        
        return result
    
    # =========================================================================
    # VERÄ° KALÄ°TE RAPORU
    # =========================================================================
    
    def quality_report(self, df: pd.DataFrame) -> Dict:
        """
        Veri kalite Ã¶zet raporu oluÅŸturur.
        
        Debug ve doÄŸrulama iÃ§in kullanÄ±lÄ±r.
        Her yeni veri kaynaÄŸÄ±nda bir kez Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±.
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        Dict
            Kalite metrikleri
        """
        report = {
            'rows': len(df),
            'columns': len(df.columns),
            'missing_total': int(df.isnull().sum().sum()),
            'missing_pct': float(df.isnull().mean().mean() * 100),
        }
        
        # Return istatistikleri (varsa)
        if 'log_return' in df.columns:
            returns = df['log_return'].dropna()
            report['return_stats'] = {
                'mean': float(returns.mean()),
                'std': float(returns.std()),
                'skew': float(returns.skew()),
                'kurt': float(returns.kurtosis()),
                'min': float(returns.min()),
                'max': float(returns.max()),
            }
        
        # Volatilite istatistikleri (varsa)
        if 'volatility' in df.columns:
            vol = df['volatility'].dropna()
            report['volatility_stats'] = {
                'current': float(vol.iloc[-1]),
                'mean': float(vol.mean()),
                'percentile_25': float(vol.quantile(0.25)),
                'percentile_75': float(vol.quantile(0.75)),
            }
        
        return report


# =============================================================================
# TEST KODU
# =============================================================================
if __name__ == "__main__":
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%H:%M:%S'
    )
    
    print("=" * 60)
    print("  PREPROCESSOR TEST")
    print("=" * 60)
    
    # Rastgele OHLCV verisi oluÅŸtur (test iÃ§in)
    np.random.seed(42)
    n = 500
    
    # Random walk fiyat serisi
    price = 50000 + np.cumsum(np.random.randn(n) * 100)
    
    df_test = pd.DataFrame({
        'open': price + np.random.randn(n) * 50,
        'high': price + abs(np.random.randn(n) * 200),
        'low': price - abs(np.random.randn(n) * 200),
        'close': price,
        'volume': np.random.exponential(1000, n),
    })
    
    # High/Low dÃ¼zelt (tutarlÄ±lÄ±k iÃ§in)
    df_test['high'] = df_test[['open', 'high', 'close']].max(axis=1) + 10
    df_test['low'] = df_test[['open', 'low', 'close']].min(axis=1) - 10
    
    # Timestamp ekle
    df_test.index = pd.date_range('2025-01-01', periods=n, freq='1h', tz='UTC')
    
    # BirkaÃ§ NaN ekle (test)
    df_test.iloc[10:12, 0] = np.nan
    
    print(f"\nTest verisi: {len(df_test)} satÄ±r, {len(df_test.columns)} kolon")
    
    # Preprocessor test
    pp = DataPreprocessor()
    
    # 1. Tek tek adÄ±mlar
    print("\n[1] Handle missing:")
    df1 = pp.handle_missing(df_test)
    
    print("\n[2] Add returns:")
    df2 = pp.add_returns(df1)
    print(f"   Return kolonlarÄ±: {[c for c in df2.columns if 'return' in c]}")
    
    print("\n[3] Winsorize:")
    df3 = pp.winsorize_returns(df2)
    
    print("\n[4] Price features:")
    df4 = pp.add_price_features(df3)
    print(f"   Yeni kolonlar: {[c for c in df4.columns if c not in df3.columns]}")
    
    print("\n[5] Rolling stats:")
    df5 = pp.add_rolling_stats(df4, windows=[10, 20])
    print(f"   Roll kolonlarÄ±: {[c for c in df5.columns if 'roll' in c]}")
    
    print("\n[6] Volatility:")
    df6 = pp.add_volatility(df5)
    print(f"   Son volatilite: {df6['volatility'].iloc[-1]:.6f}")
    
    print("\n[7] Forward returns:")
    df7 = pp.add_forward_returns(df6, periods=[1, 5])
    print(f"   Forward kolonlar: {[c for c in df7.columns if 'fwd' in c]}")
    
    # 2. Full pipeline
    print("\n" + "=" * 60)
    print("[FULL PIPELINE]")
    df_clean = pp.full_pipeline(df_test)
    print(f"   SonuÃ§: {df_clean.shape[0]} satÄ±r, {df_clean.shape[1]} kolon")
    
    # 3. Kalite raporu
    print("\n[KALÄ°TE RAPORU]")
    report = pp.quality_report(df_clean)
    for k, v in report.items():
        if isinstance(v, dict):
            print(f"   {k}:")
            for k2, v2 in v.items():
                print(f"     {k2}: {v2:.6f}" if isinstance(v2, float) else f"     {k2}: {v2}")
        else:
            print(f"   {k}: {v}")
    
    print("\n" + "=" * 60)
    print("  TÃœM TESTLER TAMAMLANDI âœ…")
    print("=" * 60)
